import client
import json
import attrorder
import itertools
import random
import csv


hostname = "dbserver02.cs.washington.edu"
port = "10032"
num_servers = 64

client.init_connection(hostname, port)

# 10 random sampled join orders, generated by sample_orders
sampled_orders = [
    (0, 1, 2, 3, 4, 5),
    (1, 2, 4, 5, 0, 3),
    (2, 1, 5, 3, 4, 0),
    (0, 3, 2, 4, 1, 5),
    (3, 0, 1, 2, 5, 4),
    (1, 3, 0, 4, 5, 2),
    (2, 4, 3, 1, 5, 0),
    (2, 4, 5, 0, 3, 1),
    (5, 0, 4, 1, 2, 3),
    (4, 0, 2, 5, 1, 3),
    (3, 2, 0, 4, 5, 1),
    (4, 5, 2, 3, 1, 0),
    (3, 2, 0, 4, 1, 5),
    (0, 5, 2, 1, 4, 3),
    (1, 2, 0, 3, 5, 4),
    (3, 5, 4, 1, 2, 0),
    (2, 5, 3, 1, 4, 0),
    (4, 2, 0, 5, 1, 3),
    (2, 0, 5, 3, 4, 1),
    (2, 4, 1, 5, 3, 0)]


def sample_orders(size, join_arity):
    all_order = list(itertools.permutations(list(range(join_arity))))
    idx = [random.randint(0, 40319) for i in range(size)]
    return [all_order[i] for i in idx]


def hypercube_shuffle():
    """
    Only hypercube shuffle
    """
    json_query_files = [
        "q1_hc_1.json", "q1_hc_2.json", "q1_hc_3.json", "q1_hc_4.json",
        "q1_hc_5.json", "q1_hc_6.json", "q1_hc_7.json", "q1_hc_8.json"]
    for query_file_path in json_query_files:
        with open(query_file_path) as jf:
            query = json.load(jf)
            print "executing query {}".format(query_file_path)
            client.execute_json(query)


def random_order_lfj(query_file, log_file_name, orders):
    with open(query_file) as f:
        json_query = json.load(f)

    with open(log_file_name, "wb") as f:
        csvwriter = csv.writer(f)
        csvwriter.writerow(["query_id", "order", "time", "success or fail"])
        for order in orders:
            json_query, a, b = attrorder.change_order(json_query, order)
            print "execute leapfrog join with order {}".format(order)
            result, status = client.execute_json(json_query)
            # log experiment result
            if result == 'success':
                print "success"
                time = float(status["elapsedNanos"]) / client.NANO_IN_ONE_SEC
                csvwriter.writerow([
                    status["queryId"], str(order), time, "success"])
            else:
                print "error"
                csvwriter.writerow(["N.A.", str(order), "N.A.", "fail"])


def execute_original_query():
    with open("q8_lfj_local.json") as f:
        json_query = json.load(f)
    new_order = (0, 1, 2, 3, 4, 5)
    print "executing {}".format(new_order)
    new_query, a, b = attrorder.change_order(json_query, new_order)
    # new_query["profilingMode"] = 'QUERY'
    result, status = client.execute_json(new_query)


def exp_q8():
    with open("q8_lfj_local.json") as f:
        json_query = json.load(f)
    for order in sampled_orders[18:]:
        # print "executing {}".format(order)
        new_query, a, b = attrorder.change_order(json_query, order)
        result, status = client.execute_json(new_query)
        if result == 'success':
            output = (order, attrorder.q8(order), float(status["elapsedNanos"]) / client.NANO_IN_ONE_SEC)
            print ",".join([str(i) for i in output])
        else:
            raise ValueError("Error when executing {}".format(order))


if __name__ == '__main__':
    exp_q8()
    # random_order_lfj(
    #    "q4_local_tj.json", "q4_single_machine_1.csv", q4_sample_orders[29:])
    # print sample_orders(30, 8)
